{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043ec213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(\"Spark AQE- DataSkew Handling\"). \\\n",
    "    master(\"yarn\"). \\\n",
    "    config('spark.executor.instances','2'). \\\n",
    "    config('spark.executor.memory','512MB'). \\\n",
    "    config('spark.executor.cores','4'). \\\n",
    "    config('spark.dynamicAllocation.enabled','False'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94beec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb2897f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application_1745651200635_11250'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6242c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Disable AQE and Broadcast join\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b21d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Employee data\n",
    "schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(schema).option(\"header\", True).load(\"Datasets/employee_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b1bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DEPT CSV data\n",
    "dept_schema = \"department_id int, department_name string, description string, city string, state string, country string\"\n",
    "\n",
    "dept = spark.read.format(\"csv\").schema(dept_schema).option(\"header\", True).load(\"Datasets/department_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511847cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the same dataframe multiple times to increase dataframe size\n",
    "\n",
    "emp_df = emp.union(emp).union(emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26327d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Datasets\n",
    "\n",
    "df_joined = emp_df.join(dept, on=emp_df.department_id==dept.department_id, how=\"left_outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53687304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to noop format - dummy write\n",
    "\n",
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4690d982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable AQE \n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", True)\n",
    "spark.conf.set(\"spark.sql.adaptive.advisoryPartitionSizeInBytes\", \"5MB\")\n",
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\",\"8MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "733daf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the datasets\n",
    "\n",
    "df_joined = emp_df.join(dept, on=emp_df.department_id==dept.department_id, how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66bc3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to noop format\n",
    "\n",
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2cfdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop the spark\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c82d0",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "1. Understand how AQE helps to avoid the Data Skewness Automatically\n",
    "2. understand how AQE reduces the empty partitions \n",
    "3. How AQE Helps to reduce the Data spill\n",
    "4. Memory spill vs Disk Spill\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
