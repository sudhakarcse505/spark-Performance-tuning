{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a85f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(\"Spark dataSkew WindowFunc\"). \\\n",
    "    master(\"yarn\"). \\\n",
    "    config('spark.executor.instances','2'). \\\n",
    "    config('spark.executor.memory','512MB'). \\\n",
    "    config('spark.executor.cores','4'). \\\n",
    "    config('spark.dynamicAllocation.enabled','False'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87487b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18af77db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application_1745651200635_12486'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d445fe",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Disable AQE and AdvisoryPartitionSize\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ef2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Employee Skew data\n",
    "schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(schema).option(\"header\", True).load(\"Datasets/employee_records_skew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8900c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "| first_name| last_name|           job_title|       dob|               email|               phone|  salary|department_id|\n",
      "+-----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "|      Jacob|     Stark|         Fine artist|1976-04-25|jasonortiz@exampl...|  224-695-9516x02171|358889.0|            1|\n",
      "|    Marissa|     Crane|Intelligence analyst|2000-06-24|johnsontroy@examp...|        277-928-0029|786608.0|            3|\n",
      "|     Andrea|     Davis|     Physiotherapist|1999-06-17| ihowell@example.org|          9503082950|428991.0|            3|\n",
      "|       John|     Tapia|Lecturer, further...|2001-09-23|russobarbara@exam...|    001-679-487-9525|241574.0|            9|\n",
      "|      Colin|    Holmes|     Psychotherapist|1965-06-29|fsimmons@example.org|          3232202899|320260.0|            4|\n",
      "|       Eric|      Beck|Speech and langua...|1970-10-28|johnny90@example.net|+1-744-277-5637x0...|125977.0|            4|\n",
      "|      Jason|    Robles|Sound technician,...|1967-03-21|jessicathomas@exa...|    001-872-480-5161|447336.0|            2|\n",
      "|   Courtney|    Daniel|     Careers adviser|1994-11-14| gmurray@example.org|  (415)357-1570x5493|514742.0|            2|\n",
      "|  Stephanie|   Morales|         Pathologist|1982-09-24|michael68@example...|001-311-431-6117x...| 14207.0|            6|\n",
      "|   Virginia| Cervantes|Chief Operating O...|1994-12-10|nicholasdavis@exa...|     +1-807-442-2027|756630.0|           10|\n",
      "|     Elijah|    Glover|Therapist, speech...|1969-10-20|brookefrederick@e...|        434.735.9681|611461.0|            8|\n",
      "|   Jennifer|   Collins|       Site engineer|1975-09-11|joseph06@example.org|     +1-416-797-0488| 19458.0|            4|\n",
      "|  Christina|      Ball|Teacher, special ...|1962-12-20| fwatson@example.org|    280.582.7025x086|709984.0|            9|\n",
      "|       Drew|  Erickson|Psychologist, edu...|1996-11-05| jason18@example.com|001-271-662-7827x...|304998.0|            3|\n",
      "|      James|    Wright|Air traffic contr...|1975-10-21|   arice@example.com|       (721)398-6804|403612.0|            4|\n",
      "|    Valerie|     Smith|      Phytotherapist|1985-04-14|frederickjames@ex...|   498.939.5081x5501|181849.0|            6|\n",
      "|Christopher|     Smith|Accountant, chart...|1970-04-01|robert20@example.net|        559-309-6778| 96578.0|            1|\n",
      "|    Patrick|     Bowen| Exhibition designer|1968-01-02|   tbell@example.net|   863-759-4636x5870|276783.0|            6|\n",
      "|      Erika|Cunningham|           Mudlogger|1974-07-02|lauren19@example.com|    688-359-8811x177|647089.0|            6|\n",
      "|    Melissa|    Murray| Librarian, academic|1985-06-14|christinaruiz@exa...|        841.594.5213| 48231.0|            5|\n",
      "+-----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e009e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the skew for department_id=2\n",
    "\n",
    "emp_df = emp.union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")) \\\n",
    "            .union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")) \\\n",
    "            .union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a148da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, avg, sum, min, max\n",
    "\n",
    "# Window function: rank events by date per user\n",
    "window_spec = Window.partitionBy(\"department_id\").orderBy(\"dob\")\n",
    "\n",
    "df_with_rank = emp_df.withColumn(\"dept_max_sal\", max(\"salary\").over(window_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16db332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to noop - takes 4 mints\n",
    "\n",
    "df_with_rank.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b457fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|               phone|  salary|department_id|dept_max_sal|\n",
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "|      Jane|    Reyes|      Air cabin crew|1962-12-17| hdunlap@example.net|        797.558.4831|658357.0|            2|    928613.0|\n",
      "|    Tyrone|    Wells|Producer, televis...|1962-12-17|brandonkelly@exam...|   530.698.2971x5231| 76400.0|            2|    928613.0|\n",
      "|       Roy|   Vargas|             Curator|1962-12-17|swansonmaria@exam...| +1-669-614-3946x041|223256.0|            2|    928613.0|\n",
      "|   Cameron|    Olson|Educational psych...|1962-12-17|lopezjames@exampl...|   (209)978-1855x159| 87142.0|            2|    928613.0|\n",
      "|      Adam|Hernandez|   Social researcher|1962-12-17|stacey60@example.net| (245)538-0234x73526|144252.0|            2|    928613.0|\n",
      "|      Dawn|  Mcbride|        Cartographer|1962-12-17|josegarcia@exampl...|        653.247.6602|141670.0|            2|    928613.0|\n",
      "|      Adam|     Webb|Occupational psyc...|1962-12-17|darlene10@example...|        240.417.5033|631124.0|            2|    928613.0|\n",
      "|     Jason|   Taylor|Advertising art d...|1962-12-17|jessicadurham@exa...|          9575831818|338240.0|            2|    928613.0|\n",
      "|  Jennifer|   Garcia|   Quantity surveyor|1962-12-17| fashley@example.org|          8516651295|617656.0|            2|    928613.0|\n",
      "|  Jennifer|  Shaffer|Chartered certifi...|1962-12-17|tamara96@example.net|   (491)917-2143x040|928613.0|            2|    928613.0|\n",
      "|      Dana|     Hall|Development worke...|1962-12-17| elarson@example.com|    927-581-4077x737|564211.0|            2|    928613.0|\n",
      "|     Sarah| Ferguson|    Engineer, energy|1962-12-17|aliciagonzalez@ex...|    986.957.6418x831| 49515.0|            2|    928613.0|\n",
      "|      Adam|     Webb|Occupational psyc...|1962-12-17|darlene10@example...|        240.417.5033|631124.0|            2|    928613.0|\n",
      "|     Jason|   Taylor|Advertising art d...|1962-12-17|jessicadurham@exa...|          9575831818|338240.0|            2|    928613.0|\n",
      "|      Anne|  Randall|Secondary school ...|1962-12-17|omartinez@example...|        462.247.5029| 24952.0|            2|    928613.0|\n",
      "|    Javier|     Hall|Broadcast journalist|1962-12-17|richard04@example...|        534-950-4325| 22499.0|            2|    928613.0|\n",
      "|      John|    Baker|Industrial/produc...|1962-12-17|smithmonica@examp...|001-697-205-7945x...|882759.0|            2|    928613.0|\n",
      "|  Jennifer|   Garcia|   Quantity surveyor|1962-12-17| fashley@example.org|          8516651295|617656.0|            2|    928613.0|\n",
      "|  Jennifer|  Shaffer|Chartered certifi...|1962-12-17|tamara96@example.net|   (491)917-2143x040|928613.0|            2|    928613.0|\n",
      "|      Dana|     Hall|Development worke...|1962-12-17| elarson@example.com|    927-581-4077x737|564211.0|            2|    928613.0|\n",
      "+----------+---------+--------------------+----------+--------------------+--------------------+--------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rank.where(\"department_id == 2\").orderBy(\"dob\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc263fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please check the Spark Ui -> SQL -> Job -> Stage -> Task details\n",
    "#Observe the dataSkew Issues\n",
    "#Observe the DataSpill Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8904c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|partition_num| count|\n",
      "+-------------+------+\n",
      "|           10|  8713|\n",
      "|            9| 60703|\n",
      "|            8| 65250|\n",
      "|            7| 65699|\n",
      "|            6|217684|\n",
      "|            5|130421|\n",
      "|            4|130312|\n",
      "|            3|130393|\n",
      "|            2|130400|\n",
      "|            1|130384|\n",
      "|            0|130406|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition count\n",
    "from pyspark.sql.functions import spark_partition_id, count, lit, desc\n",
    "\n",
    "part_df = emp_df.withColumn(\"partition_num\", spark_partition_id()).groupBy(\"partition_num\").agg(count(lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.orderBy(desc(\"partition_num\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "276ac74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|department_id|count(1)|\n",
      "+-------------+--------+\n",
      "|            4|  100214|\n",
      "|            8|  100417|\n",
      "|            7|   99805|\n",
      "|           10|   99780|\n",
      "|            1|   99451|\n",
      "|            6|   99706|\n",
      "|            3|  100248|\n",
      "|            5|  200420|\n",
      "|            2|  200310|\n",
      "|            9|  100014|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Employee data based on department_id\n",
    "from pyspark.sql.functions import count, lit, desc, col\n",
    "\n",
    "emp_df.groupBy(\"department_id\").agg(count(lit(1))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d892f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit, rand, floor\n",
    "\n",
    "#salting\n",
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# UDF to return a random number every time and add to Employee as salt\n",
    "@udf\n",
    "def salt_udf():\n",
    "    return random.randint(0, 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2baa49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting shuffle partition same as salted keys range\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b26332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a salted key (simulate evenly spreading records)\n",
    "\n",
    "salted_emp = emp.withColumn(\"salted_dept_id\", concat(\"department_id\", lit(\"_\"), salt_udf()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31b70b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|salted_dept_id| cnt|\n",
      "+--------------+----+\n",
      "|          5_18|4254|\n",
      "|          2_18|4238|\n",
      "|          5_28|4237|\n",
      "|          2_20|4201|\n",
      "|           5_5|4189|\n",
      "|          5_10|4187|\n",
      "|          5_47|4185|\n",
      "|           5_1|4178|\n",
      "|          2_31|4174|\n",
      "|          5_17|4173|\n",
      "|           5_3|4170|\n",
      "|          5_27|4169|\n",
      "|          5_14|4169|\n",
      "|           5_8|4164|\n",
      "|          5_44|4160|\n",
      "|          2_45|4155|\n",
      "|          5_29|4153|\n",
      "|          2_30|4148|\n",
      "|          2_12|4147|\n",
      "|          5_30|4144|\n",
      "+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Employee data based on department_id\n",
    "from pyspark.sql.functions import count, lit, desc, col\n",
    "\n",
    "salted_emp.groupBy(\"salted_dept_id\").agg(count(lit(1)).alias(\"cnt\")).orderBy(desc(\"cnt\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818efe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply window function on salted key\n",
    "\n",
    "window_salted = Window.partitionBy(\"salted_dept_id\").orderBy(\"dob\")\n",
    "\n",
    "df_salted_max_sal = salted_emp.withColumn(\"dept_max_sal_salt\", max(\"salary\").over(window_salted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1aa9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by on dept to get actual result\n",
    "wind = Window.partitionBy(\"department_id\").orderBy(\"dob\")\n",
    "\n",
    "df_final_wdw = df_salted_max_sal.withColumn(\"dept_max_sal\", max(\"dept_max_sal_salt\").over(wind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "683a0b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to noop\n",
    "\n",
    "df_final_wdw.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41cd6088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+-------------+--------------+-----------------+------------+\n",
      "|first_name|last_name|       dob|  salary|department_id|salted_dept_id|dept_max_sal_salt|dept_max_sal|\n",
      "+----------+---------+----------+--------+-------------+--------------+-----------------+------------+\n",
      "|    Tyrone|    Wells|1962-12-17| 76400.0|            2|          2_90|          87142.0|    928613.0|\n",
      "|    Javier|     Hall|1962-12-17| 22499.0|            2|          2_71|          22499.0|    928613.0|\n",
      "|   Cameron|    Olson|1962-12-17| 87142.0|            2|          2_90|          87142.0|    928613.0|\n",
      "|      Adam|     Webb|1962-12-17|631124.0|            2|          2_15|         631124.0|    928613.0|\n",
      "|    Javier|     Hall|1962-12-17| 22499.0|            2|          2_47|          22499.0|    928613.0|\n",
      "|      Adam|Hernandez|1962-12-17|144252.0|            2|          2_15|         631124.0|    928613.0|\n",
      "|      Dawn|  Mcbride|1962-12-17|141670.0|            2|          2_28|         141670.0|    928613.0|\n",
      "|      Jane|    Reyes|1962-12-17|658357.0|            2|          2_79|         658357.0|    928613.0|\n",
      "|     Sarah| Ferguson|1962-12-17| 49515.0|            2|           2_5|          49515.0|    928613.0|\n",
      "|      Anne|  Randall|1962-12-17| 24952.0|            2|          2_19|          24952.0|    928613.0|\n",
      "|      Dana|     Hall|1962-12-17|564211.0|            2|          2_59|         564211.0|    928613.0|\n",
      "|     Sarah| Ferguson|1962-12-17| 49515.0|            2|          2_93|          49515.0|    928613.0|\n",
      "|  Jennifer|  Shaffer|1962-12-17|928613.0|            2|          2_72|         928613.0|    928613.0|\n",
      "|   Cameron|    Olson|1962-12-17| 87142.0|            2|           2_4|         617656.0|    928613.0|\n",
      "|  Jennifer|   Garcia|1962-12-17|617656.0|            2|           2_4|         617656.0|    928613.0|\n",
      "|     Jason|   Taylor|1962-12-17|338240.0|            2|          2_80|         928613.0|    928613.0|\n",
      "|  Jennifer|  Shaffer|1962-12-17|928613.0|            2|          2_80|         928613.0|    928613.0|\n",
      "|      Jane|    Reyes|1962-12-17|658357.0|            2|          2_80|         928613.0|    928613.0|\n",
      "|      John|    Baker|1962-12-17|882759.0|            2|          2_24|         882759.0|    928613.0|\n",
      "|      Anne|  Randall|1962-12-17| 24952.0|            2|          2_76|          24952.0|    928613.0|\n",
      "+----------+---------+----------+--------+-------------+--------------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the salt column\n",
    "\n",
    "df_final_wdw.drop(\"job_title\",\"email\",\"phone\").where(\"department_id == 2\").orderBy(\"dob\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fa8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop sparkSession\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea8bbc",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "1. understand data skew in Aggregation or window functions\n",
    "2. understand data spill to memory and Disk\n",
    "3. how to prepare the salted key\n",
    "4. how to reduce spills using salting approch\n",
    "5. AQE can't handle the Aggregate or Window functions \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
