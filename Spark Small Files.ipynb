{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7300fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(\"Spark Small files Test\"). \\\n",
    "    master(\"yarn\"). \\\n",
    "    config('spark.executor.instances','2'). \\\n",
    "    config('spark.executor.memory','2GB'). \\\n",
    "    config('spark.executor.cores','2'). \\\n",
    "    config('spark.dynamicAllocation.enabled','False'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "595ff0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e60e28a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application_1745651200635_5740'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dad694d",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Disable AQE and Broadcast join\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3355faae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'134217728b'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#default config is 128MB\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6ad8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files with many small files default 128MB\n",
    "\n",
    "emp_128_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fe8cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_128_part.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 25 S\n",
    "#Number of partition: 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7c86665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'67108864'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max partition size reduce to 64MB\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\",64 * 1024 * 1024)\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf649593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emp_64_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53a47475",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_64_part.write.format(\"noop\").mode(\"overwrite\").save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c35253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 34 S\n",
    "#Number of partition: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b5300a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'268435456'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max partition size increase to 256MB\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 256 * 1024 * 1024)\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e6675fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_256_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fde8272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_256_part.write.format(\"noop\").mode(\"overwrite\").save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c831edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 22 Sec\n",
    "#Number of partition: 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ed07a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'536870912'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max partition size increase to 512MB\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 512 * 1024 * 1024)\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22a53c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_512_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "997fab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_512_part.write.format(\"noop\").mode(\"overwrite\").save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 23 Sec\n",
    "#Number of partition: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9790721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'403701760'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max partition size increase to 385MB\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 385 * 1024 * 1024)\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9b43355",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_385_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ad66e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_385_part.write.format(\"noop\").mode(\"overwrite\").save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 23 Sec\n",
    "#Number of partition: 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9178c117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201326592'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max partition size increase to 192MB\n",
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 192 * 1024 * 1024)\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe6c4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_192_part = spark.read.parquet(\"BigDataset/employee_records_10GB_parquet_5mb_small_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b49e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_192_part.write.format(\"noop\").mode(\"overwrite\").save() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2642fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time taken to process: 29 Sec\n",
    "#Number of partition: 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e80c99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion:\n",
    "How to read many small files \n",
    "how to combine while reading small partitions to large enough to save cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09772bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
