{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7d8f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.ui.port\", \"0\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(\"Spark dataSkew Window Dense_Rank\"). \\\n",
    "    master(\"yarn\"). \\\n",
    "    config('spark.executor.instances','5'). \\\n",
    "    config('spark.executor.memory','512MB'). \\\n",
    "    config('spark.executor.cores','4'). \\\n",
    "    config('spark.dynamicAllocation.enabled','False'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c4078f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50ce3391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application_1745651200635_18450'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97ab248c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Disable AQE and AdvisoryPartitionSize\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "385545f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Employee Skew data\n",
    "schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format(\"csv\").schema(schema).option(\"header\", True).load(\"Datasets/employee_records_skew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7df4e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "|first_name| last_name|           job_title|       dob|               email|               phone|  salary|department_id|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|       (699)525-4827|512653.0|            8|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|  (750)846-1602x7458|999836.0|            7|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24| jturner@example.net|    873.820.0518x825|131900.0|           10|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16|  erik33@example.net|    820-813-0557x624|485506.0|            1|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|       (705)900-5337|604738.0|            8|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16|patrickalexandra@...|        211.440.5466|483339.0|            6|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28|  lori44@example.net|        936-403-3179|419644.0|            7|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01| ygordon@example.org|       (889)246-5588|205939.0|            7|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16| diana44@example.net|001-647-530-5036x...|671167.0|            8|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28|  ryan36@example.com|   422.562.7254x3159|993829.0|            7|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11|monica93@example.org|+1-535-652-9715x6...|702101.0|            4|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01|stephanie65@examp...|   (652)815-7973x298|570960.0|            6|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17|pwilliams@example...|001-245-848-0028x...|339441.0|            6|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18|gabrielmurray@exa...|          9247590563|469728.0|            8|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13|nicholas76@exampl...|   311.439.1606x3342|582291.0|            4|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07|  mark07@example.com|    001-912-206-6456|146456.0|            4|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02|griffinmary@examp...| +1-791-344-7586x548|544732.0|            1|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12|alexandraobrien@e...|        216.696.6061|399503.0|            3|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10|  rmorse@example.org|  (726)363-7526x9965|761988.0|           10|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02|brandoncardenas@e...| (964)451-9007x22496|660659.0|            4|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32d11e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the skew for department_id=2\n",
    "emp1 = emp.drop(\"job_title\",\"email\",\"phone\")\n",
    "\n",
    "emp_df = emp1 #.union(emp1.where(\"department_id == 2\")).union(emp1.where(\"department_id == 2\")).union(emp1.where(\"department_id == 2\")) \\\n",
    "             #.union(emp1.where(\"department_id == 2\")).union(emp1.where(\"department_id == 2\")).union(emp1.where(\"department_id == 2\"))\n",
    "            # .union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\")).union(emp.where(\"department_id == 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fb4bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, avg, sum, min, max, dense_rank, desc\n",
    "\n",
    "# Window function: rank events by date per user\n",
    "window_spec = Window.partitionBy(\"department_id\").orderBy(desc(\"salary\"))\n",
    "\n",
    "df_with_rank = emp_df.withColumn(\"dense_rank\", dense_rank().over(window_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd4ccc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to noop - \n",
    "\n",
    "df_with_rank.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7082a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+-------------+----------+\n",
      "|first_name|last_name|       dob|  salary|department_id|dense_rank|\n",
      "+----------+---------+----------+--------+-------------+----------+\n",
      "|   Richard|   Foster|1990-03-26|999997.0|            2|         1|\n",
      "|   Richard|   Foster|1990-03-26|999997.0|            2|         1|\n",
      "|   Cynthia|    Lewis|1994-05-15|999987.0|            2|         2|\n",
      "|   Cynthia|    Lewis|1994-05-15|999987.0|            2|         2|\n",
      "|    Melody| Reynolds|1987-09-11|999964.0|            2|         3|\n",
      "|    Melody| Reynolds|1987-09-11|999964.0|            2|         3|\n",
      "|    Thomas|   Medina|1997-08-10|999903.0|            2|         4|\n",
      "|    Thomas|   Medina|1997-08-10|999903.0|            2|         4|\n",
      "|    Andrea|   Gordon|1998-06-07|999885.0|            2|         5|\n",
      "|    Andrea|   Gordon|1998-06-07|999885.0|            2|         5|\n",
      "|    Donald|    Jones|1977-03-29|999875.0|            2|         6|\n",
      "|    Donald|    Jones|1977-03-29|999875.0|            2|         6|\n",
      "|     Tammy|   Finley|1966-10-08|999873.0|            2|         7|\n",
      "|     Tammy|   Finley|1966-10-08|999873.0|            2|         7|\n",
      "| Christian|   Martin|1973-07-26|999857.0|            2|         8|\n",
      "| Christian|   Martin|1973-07-26|999857.0|            2|         8|\n",
      "|      Lori|   Kelley|1988-03-07|999856.0|            2|         9|\n",
      "|      Lori|   Kelley|1988-03-07|999856.0|            2|         9|\n",
      "+----------+---------+----------+--------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#some sample data with row_number\n",
    "\n",
    "df_with_rank.where(\"department_id == 2\").where(\"dense_rank < 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd56e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please check the Spark Ui -> SQL -> Job -> Stage -> Task details\n",
    "#Observe the dataSkew Issues\n",
    "#Observe the DataSpill Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ef825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|partition_num| count|\n",
      "+-------------+------+\n",
      "|           19|  8713|\n",
      "|           18| 21699|\n",
      "|           17| 25986|\n",
      "|           16| 26064|\n",
      "|           15| 26090|\n",
      "|           14| 26114|\n",
      "|           13| 26128|\n",
      "|           12| 26275|\n",
      "|           11| 32533|\n",
      "|           10| 38454|\n",
      "|            9| 38519|\n",
      "|            8| 38449|\n",
      "|            7| 87281|\n",
      "|            6|111102|\n",
      "|            5|111166|\n",
      "|            4|111166|\n",
      "|            3|111129|\n",
      "|            2|111145|\n",
      "|            1|111175|\n",
      "|            0|111177|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the partition count\n",
    "from pyspark.sql.functions import spark_partition_id, count, lit, desc\n",
    "\n",
    "part_df = emp_df.withColumn(\"partition_num\", spark_partition_id()).groupBy(\"partition_num\").agg(count(lit(1)).alias(\"count\"))\n",
    "\n",
    "part_df.orderBy(desc(\"partition_num\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd59308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|department_id|count(1)|\n",
      "+-------------+--------+\n",
      "|            1|   99451|\n",
      "|            6|   99706|\n",
      "|            3|  100248|\n",
      "|            5|  200420|\n",
      "|            9|  100014|\n",
      "|            4|  100214|\n",
      "|            8|  100417|\n",
      "|            7|   99805|\n",
      "|           10|   99780|\n",
      "|            2|  200310|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify Employee data based on department_id\n",
    "from pyspark.sql.functions import count, lit, desc, col\n",
    "\n",
    "emp_df.groupBy(\"department_id\").agg(count(lit(1))).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54684232",
   "metadata": {},
   "source": [
    " Dense_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f02fd84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get distinct (department_id, salary)\n",
    "salary_distinct = emp_df.select(\"department_id\", \"salary\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd65c042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----+\n",
      "|department_id|  salary|rank|\n",
      "+-------------+--------+----+\n",
      "|            1|999996.0|   1|\n",
      "|            1|999979.0|   2|\n",
      "|            1|999959.0|   3|\n",
      "|            1|999922.0|   4|\n",
      "|            1|999917.0|   5|\n",
      "|            1|999914.0|   6|\n",
      "|            1|999911.0|   7|\n",
      "|            1|999901.0|   8|\n",
      "|            1|999896.0|   9|\n",
      "|            1|999894.0|  10|\n",
      "|            1|999885.0|  11|\n",
      "|            1|999879.0|  12|\n",
      "|            1|999863.0|  13|\n",
      "|            1|999849.0|  14|\n",
      "|            1|999846.0|  15|\n",
      "|            1|999844.0|  16|\n",
      "|            1|999843.0|  17|\n",
      "|            1|999829.0|  18|\n",
      "|            1|999815.0|  19|\n",
      "|            1|999809.0|  20|\n",
      "+-------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Use dense_rank() over department_id, order by salary desc\n",
    "# This is safe because it's only over distinct values => no skew\n",
    "\n",
    "drank_window = Window.partitionBy(\"department_id\").orderBy(col(\"salary\").desc())\n",
    "salary_drank_df = salary_distinct.withColumn(\"rank\", dense_rank().over(drank_window))\n",
    "salary_drank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "273f9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Join back to assign rank to full dataset\n",
    "\n",
    "final_drank_df = emp_df.join(salary_drank_df, on=[\"department_id\", \"salary\"], how=\"inner\") \\\n",
    "              .select(\"*\") \\\n",
    "              .orderBy(\"department_id\", \"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "024d16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to noop - takes 8 Sec\n",
    "\n",
    "final_drank_df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb9712cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+---------+----------+----+\n",
      "|department_id|  salary|first_name|last_name|       dob|rank|\n",
      "+-------------+--------+----------+---------+----------+----+\n",
      "|            2|999997.0|   Richard|   Foster|1990-03-26|   1|\n",
      "|            2|999997.0|   Richard|   Foster|1990-03-26|   1|\n",
      "|            2|999987.0|   Cynthia|    Lewis|1994-05-15|   2|\n",
      "|            2|999987.0|   Cynthia|    Lewis|1994-05-15|   2|\n",
      "|            2|999964.0|    Melody| Reynolds|1987-09-11|   3|\n",
      "|            2|999964.0|    Melody| Reynolds|1987-09-11|   3|\n",
      "|            2|999903.0|    Thomas|   Medina|1997-08-10|   4|\n",
      "|            2|999903.0|    Thomas|   Medina|1997-08-10|   4|\n",
      "|            2|999885.0|    Andrea|   Gordon|1998-06-07|   5|\n",
      "|            2|999885.0|    Andrea|   Gordon|1998-06-07|   5|\n",
      "|            2|999875.0|    Donald|    Jones|1977-03-29|   6|\n",
      "|            2|999875.0|    Donald|    Jones|1977-03-29|   6|\n",
      "|            2|999873.0|     Tammy|   Finley|1966-10-08|   7|\n",
      "|            2|999873.0|     Tammy|   Finley|1966-10-08|   7|\n",
      "|            2|999857.0| Christian|   Martin|1973-07-26|   8|\n",
      "|            2|999857.0| Christian|   Martin|1973-07-26|   8|\n",
      "|            2|999856.0|      Lori|   Kelley|1988-03-07|   9|\n",
      "|            2|999856.0|      Lori|   Kelley|1988-03-07|   9|\n",
      "+-------------+--------+----------+---------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#some sample data with row_number\n",
    "\n",
    "final_drank_df.where(\"department_id == 2\").where(\"rank < 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aabd5433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+--------+-------------+----------+\n",
      "|first_name|last_name|       dob|  salary|department_id|dense_rank|\n",
      "+----------+---------+----------+--------+-------------+----------+\n",
      "|   Richard|   Foster|1990-03-26|999997.0|            2|         1|\n",
      "|   Richard|   Foster|1990-03-26|999997.0|            2|         1|\n",
      "|   Cynthia|    Lewis|1994-05-15|999987.0|            2|         2|\n",
      "|   Cynthia|    Lewis|1994-05-15|999987.0|            2|         2|\n",
      "|    Melody| Reynolds|1987-09-11|999964.0|            2|         3|\n",
      "|    Melody| Reynolds|1987-09-11|999964.0|            2|         3|\n",
      "|    Thomas|   Medina|1997-08-10|999903.0|            2|         4|\n",
      "|    Thomas|   Medina|1997-08-10|999903.0|            2|         4|\n",
      "|    Andrea|   Gordon|1998-06-07|999885.0|            2|         5|\n",
      "|    Andrea|   Gordon|1998-06-07|999885.0|            2|         5|\n",
      "|    Donald|    Jones|1977-03-29|999875.0|            2|         6|\n",
      "|    Donald|    Jones|1977-03-29|999875.0|            2|         6|\n",
      "|     Tammy|   Finley|1966-10-08|999873.0|            2|         7|\n",
      "|     Tammy|   Finley|1966-10-08|999873.0|            2|         7|\n",
      "| Christian|   Martin|1973-07-26|999857.0|            2|         8|\n",
      "| Christian|   Martin|1973-07-26|999857.0|            2|         8|\n",
      "|      Lori|   Kelley|1988-03-07|999856.0|            2|         9|\n",
      "|      Lori|   Kelley|1988-03-07|999856.0|            2|         9|\n",
      "+----------+---------+----------+--------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#some sample data with row_number\n",
    "\n",
    "df_with_rank.where(\"department_id == 2\").where(\"dense_rank < 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d18f28",
   "metadata": {},
   "source": [
    "✅ Summary:\n",
    "    \n",
    "1. With this approch we were able to solve this problem with 60% less resources and improved Job execution time by 80%\n",
    "2. If you try with larger datasets, you will definatly see performance improvements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b349632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
